


************************ 1.概要 ************************

DockerでPythonのデータ分析環境を構築

分析対象データ　：　CSVファイル
分析環境　　　　：　Jupyter Notebook



************************ 2.使用ライブラリ ************************

pandas: データ操作・解析ライブラリ。CSVファイルの読み込み、データフレーム操作に使用。
numpy: 数値計算用ライブラリ。高速な数値演算や配列操作を行うために使用。
matplotlib: グラフやチャートの作成を行うための可視化ライブラリ。
seaborn: matplotlib を基盤としたデータ可視化ライブラリ。スタイリッシュな統計グラフを簡単に作成可能。
scikit-learn: 機械学習ライブラリ。分類、回帰、クラスタリングなどの基本的な機械学習アルゴリズムを提供。
statsmodels: 統計解析ライブラリ。線形回帰や時系列解析など、詳細な統計モデルの構築に使用。
scipy: 科学技術計算向けライブラリ。数値積分、最適化、信号処理などに使用。
xgboost: 勾配ブースティング決定木（GBDT）を使用した機械学習モデル。
lightgbm: 軽量かつ高速な勾配ブースティングライブラリ。大規模データセットでの訓練に向いている。
tensorflow: ディープラーニングフレームワーク。ニューラルネットワークの訓練や推論を行うために使用。
keras: 高レベルのニューラルネットワークAPI。tensorflow上で動作し、簡単にモデルを構築できる。
nltk: 自然言語処理ライブラリ。テキスト処理や言語データの分析に使用。
spacy: 高速で効率的な自然言語処理ライブラリ。テキスト解析、名前付きエンティティ認識などに使用。
openpyxl: Excelファイルの読み書きを行うライブラリ。CSV以外のデータ形式もサポート。



************************ 3.注意事項 ************************

local環境でのみ使用すること

理由
今回トークンなしで、Jupyter Notebookアクセスを許可
インターネット上に公開された環境では、トークンやパスワード認証を有効にしてセキュリティを強化することが推奨




************************ 4.ディレクトリ構成 ************************

python＿test/
├── Dockerfile                # Dockerイメージの定義
├── docker-compose.yml         # Docker Compose設定ファイル
├── data/                      # CSVファイルなどのデータを管理するディレクトリ
│   └── test_data.csv          # サンプルデータ
└── notebooks/                 # Jupyter Notebookファイルを保存するディレクトリ
    └── test_analysis.ipynb    # 分析用ノートブック

data/　　　　: 分析したいCSVファイル格納
notebooks/　: Pythonの分析コードを格納

notebooks/.ipynb_checkpoints/ : 自動保存ファイル。不要であれば削除しても問題なし


************************ 5.docker起動 ************************

python_testのディレクトリで、下記実行

コンテナ起動コマンド
docker compose up -d --build

起動後、下記へアクセス
http://localhost:8888

コンテナの停止
docker compose down

